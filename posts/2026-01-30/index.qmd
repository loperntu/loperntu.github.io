---
title: "人文 AI"
description: "文學院的未來？"
author:
  - name: Shu-Kai Hsieh
    url: https://loperntu.github.io/
    orcid: 0000-0001-9674-1249
    # affiliation: 台大語言學研究所 LOPE Lab
    # affiliation-url: https://lope.github.io/ 
date: 01-30-2026
categories: [Humanities and AI] # 可以填入分類，例如：[Quantum Semantics]
citation: 
  url: https://loperntu.github.io/posts/2026-01-30/ 
image: preview_image.jpg
draft: false # 設為 true 時，文章不會出現在列表頁，直到你準備好發布
---


## AI 時代的「關鍵能力」其實是人文能力

**例子 1｜誰能問對問題？**

* 同一個 AI，一般學生問：「幫我摘要這篇文章。」
* 受過文史哲訓練的學生應該會要問：「這段論證的前提是什麼？它隱含了哪個時代的價值觀？如果換成東亞語境，結論還成立嗎？」

**差異不在 AI，而在提問者的詮釋框架。**
這正是文學院應該訓練的能力：**概念史、脈絡化、問題重構**。

---

## 修正 AI 偏見，本質是「人文判斷」

**例子 2｜AI 的偏見不是 bug，是文化產物**

* AI 在法律、性別、族群、歷史敘事上的偏誤，往往來自：
  * 英語中心的語料
  * 西方近代自由主義的價值預設

* 能「看出這種問題」的人，不是期待最會寫程式的，而是**懂得比較文明、歷史、思想傳統的人**。


文學院可以直接產出：
**「AI 偏見診斷模組」**（Bias Audit for LLMs）
由哲學、歷史、語言學共同設計測試題，而非只靠 accuracy。

---

## 鑑定 AI 產出好壞，是「高階閱讀能力」

**例子 3｜AI 很會寫，但不一定「對」**

* AI 可以生成看似完美的歷史解釋，但可能涉及：

  * 時代錯置（anachronism）
  * 概念混用（把現代概念硬套古代文本）
  * 修辭流暢但論證空洞

**能辨識這些問題的，是訓練過精讀、詮釋、文本批判的人。**
這是文學院學生每天在做、但過去「無法量化」的能力，也是文學院應該訓練的能力。

---

## 從「會用 AI」到「駕馭 AI」

**例子 4｜多輪對話不是聊天，是論證工程**

* 與 AI 的高品質互動其實是：

  1. 設定問題邊界
  2. 拆解假設
  3. 逐步修正
  4. 要求反證與替代解釋

這正是：

* 哲學的辯證訓練
* 歷史的反事實思考
* 文學的多重視角解讀


如果學生不懂歷史與概念史，他們無法發現 AI 把現代價值硬套進古代文本；
如果沒有哲學訓練，他們無法拆解 AI 論證中的隱含前提；
如果沒有語言與敘事敏感度，他們只會被「寫得很順」的錯誤答案帶著走。

換句話說：**文學院是在教「如何成為 AI 的導演，而不是打字員」。**

---

未來教育的關鍵不在答案，而在三件事：
問對問題、修正偏見、鑑定品質。這三件事，正是人文教育最成熟、卻長期被低估的能力。


## 給決策者們的一句「投資語言」


> 「AI 已經會給答案，但未來社會最缺的，是能判斷哪些答案值得相信、哪些問題值得問的人。
> 文學院不是 AI 時代的成本中心，而是 **整個大學 AI 素養的控制塔**。」
> 文學院也不是 AI 時代的防守單位，而是與 AI 共舞的判斷力的中樞投資。

如果 AI 是放大器，文學院確保我們放大的不是偏見與錯誤。

## QA

### Q1｜「這不就是在教 prompt engineering 嗎？為什麼一定要文學院？」

**短答版**
不是。Prompt engineering 是讓 AI 更快給答案，我們做的是讓學生知道什麼時候不該相信答案。

**補強版**

- Prompt 是操作層，人文訓練是判斷層
* AI 偏見、時代錯置、價值預設，無法靠技巧修正
* 文學院訓練的是：概念史、詮釋、反證與多重視角。我們教的是「如何拆解 AI 的論證」，不是如何取悅 AI。